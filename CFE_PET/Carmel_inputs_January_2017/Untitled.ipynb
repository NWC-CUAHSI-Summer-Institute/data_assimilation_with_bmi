{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1af0fe-e677-4cdb-aa91-1658aeb1ae99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./forcings_jan/cat-3400554.csv\n",
      "./forcings_jan/cat-3400594.csv\n",
      "./forcings_jan/cat-3400586.csv\n",
      "./forcings_jan/cat-3400599.csv\n",
      "./forcings_jan/cat-3400572.csv\n",
      "./forcings_jan/cat-3400551.csv\n",
      "./forcings_jan/cat-3400605.csv\n",
      "./forcings_jan/cat-3400608.csv\n",
      "./forcings_jan/cat-3400616.csv\n",
      "./forcings_jan/cat-3400573.csv\n",
      "./forcings_jan/cat-3400587.csv\n",
      "./forcings_jan/cat-3400564.csv\n",
      "./forcings_jan/cat-3400582.csv\n",
      "./forcings_jan/cat-3400602.csv\n",
      "./forcings_jan/cat-3400591.csv\n",
      "./forcings_jan/cat-3400575.csv\n",
      "./forcings_jan/cat-3400584.csv\n",
      "./forcings_jan/cat-3400626.csv\n",
      "./forcings_jan/cat-3400609.csv\n",
      "./forcings_jan/cat-3400598.csv\n",
      "./forcings_jan/cat-3400561.csv\n",
      "./forcings_jan/cat-3400611.csv\n",
      "./forcings_jan/cat-3400606.csv\n",
      "./forcings_jan/cat-3400628.csv\n",
      "./forcings_jan/cat-3400580.csv\n",
      "./forcings_jan/cat-3400567.csv\n",
      "./forcings_jan/cat-3400560.csv\n",
      "./forcings_jan/cat-3400577.csv\n",
      "./forcings_jan/cat-3400629.csv\n",
      "./forcings_jan/cat-3400579.csv\n",
      "./forcings_jan/cat-3400570.csv\n",
      "./forcings_jan/cat-3400585.csv\n",
      "./forcings_jan/cat-3400556.csv\n",
      "./forcings_jan/cat-3400549.csv\n",
      "./forcings_jan/cat-3400604.csv\n",
      "./forcings_jan/cat-3400571.csv\n",
      "./forcings_jan/cat-3400569.csv\n",
      "./forcings_jan/cat-3400624.csv\n",
      "./forcings_jan/cat-3400578.csv\n",
      "./forcings_jan/cat-3400618.csv\n",
      "./forcings_jan/cat-3400620.csv\n",
      "./forcings_jan/cat-3400595.csv\n",
      "./forcings_jan/cat-3400546.csv\n",
      "./forcings_jan/cat-3400597.csv\n",
      "./forcings_jan/cat-3400558.csv\n",
      "./forcings_jan/cat-3400622.csv\n",
      "./forcings_jan/cat-3400634.csv\n",
      "./forcings_jan/cat-3400565.csv\n",
      "./forcings_jan/cat-3400613.csv\n",
      "./forcings_jan/cat-3400574.csv\n",
      "./forcings_jan/cat-3400630.csv\n",
      "./forcings_jan/cat-3400623.csv\n",
      "./forcings_jan/cat-3400568.csv\n",
      "./forcings_jan/cat-3400603.csv\n",
      "./forcings_jan/cat-3400589.csv\n",
      "./forcings_jan/cat-3400607.csv\n",
      "./forcings_jan/cat-3400566.csv\n",
      "./forcings_jan/cat-3400553.csv\n",
      "./forcings_jan/cat-3400544.csv\n",
      "./forcings_jan/cat-3400588.csv\n",
      "./forcings_jan/cat-3400592.csv\n",
      "./forcings_jan/cat-3400632.csv\n",
      "./forcings_jan/cat-3400600.csv\n",
      "./forcings_jan/cat-3400563.csv\n",
      "./forcings_jan/cat-3400562.csv\n",
      "./forcings_jan/cat-3400576.csv\n",
      "./forcings_jan/cat-3400583.csv\n",
      "./forcings_jan/cat-3400550.csv\n",
      "./forcings_jan/cat-3400548.csv\n",
      "./forcings_jan/cat-3400601.csv\n",
      "./forcings_jan/cat-3400596.csv\n",
      "./forcings_jan/cat-3400617.csv\n",
      "./forcings_jan/cat-3400590.csv\n",
      "./forcings_jan/cat-3400545.csv\n",
      "./forcings_jan/cat-3400615.csv\n",
      "./forcings_jan/cat-3400559.csv\n",
      "./forcings_jan/cat-3400557.csv\n",
      "./forcings_jan/cat-3400619.csv\n",
      "./forcings_jan/cat-3400633.csv\n",
      "./forcings_jan/cat-3400614.csv\n",
      "./forcings_jan/cat-3400621.csv\n",
      "./forcings_jan/cat-3400631.csv\n",
      "./forcings_jan/cat-3400543.csv\n",
      "./forcings_jan/cat-3400552.csv\n",
      "./forcings_jan/cat-3400627.csv\n",
      "./forcings_jan/cat-3400610.csv\n",
      "./forcings_jan/cat-3400547.csv\n",
      "./forcings_jan/cat-3400581.csv\n",
      "./forcings_jan/cat-3400593.csv\n",
      "./forcings_jan/cat-3400625.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the directory containing your CSV files\n",
    "directory = './forcings_jan'\n",
    "num_columns = len(df.columns)\n",
    "# Create a DataFrame with 10 rows of zeros, match the number of columns with your CSV files\n",
    "new_rows = pd.DataFrame([[0]*num_columns]*10)\n",
    "\n",
    "# Generate a list of all CSV files in the specified directory\n",
    "csv_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# Loop through each file and append the data\n",
    "for file in csv_files:\n",
    "    print(file)\n",
    "    # Read the original data\n",
    "    df = pd.read_csv(file)\n",
    "    num_columns = len(df.columns)\n",
    "    # Create a DataFrame with 10 rows of zeros, match the number of columns with your CSV files\n",
    "    new_rows = pd.DataFrame([[0]*num_columns]*10)\n",
    "    # Append the new rows\n",
    "    df = pd.concat([new_rows,df], ignore_index=True)\n",
    "    \n",
    "    # Write the DataFrame back to CSV\n",
    "    df.to_csv(file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81736d92-8fee-49ef-a592-5faffc1cc3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "# Specify the directory containing your CSV files\n",
    "directory = './forcings_jan'\n",
    "\n",
    "# Generate a list of all CSV files in the specified directory\n",
    "csv_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# Loop through each file and append the data\n",
    "for file in csv_files:\n",
    "    # Read the original data\n",
    "    df = pd.read_csv(file, parse_dates=True, index_col=0)\n",
    "    \n",
    "    # Determine the time difference between rows\n",
    "    time_diff = df.index[1] - df.index[0]\n",
    "\n",
    "    # Create new indices for the rows to be added\n",
    "    earliest_time = df.index[0]\n",
    "    new_indices = pd.date_range(start=earliest_time - 10*time_diff, periods=10, freq=time_diff)\n",
    "    \n",
    "    # Create a new DataFrame with 10 rows of zeros\n",
    "    new_rows = pd.DataFrame(0, index=new_indices, columns=df.columns)\n",
    "    \n",
    "    # Append the new rows to the start\n",
    "    df = pd.concat([new_rows, df])\n",
    "    \n",
    "    # Write the DataFrame back to CSV\n",
    "    df.to_csv(file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5760c72c-f858-4f62-8e08-aa8c7d7dc54b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directories\n",
    "dir1 = './December_2016'\n",
    "dir2 = './forcings'\n",
    "\n",
    "# Get list of file names in each directory (assuming they are the same)\n",
    "filenames = os.listdir(dir1)\n",
    "\n",
    "# Loop through the file names\n",
    "for filename in filenames:\n",
    "    # Form the full file path\n",
    "    file1 = os.path.join(dir1, filename)\n",
    "    file2 = os.path.join(dir2, filename)\n",
    "\n",
    "    # Read the CSV files into pandas dataframes\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    # Concatenate the dataframes vertically\n",
    "    combined_df = pd.concat([df1, df2])\n",
    "\n",
    "    # Write the combined dataframe to a new CSV file\n",
    "    combined_df.to_csv(f'combined/{filename}', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
